{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': '/Users/tianyudu/Documents/Academics/EconForecasting/AnnEconForecast/data/UNRATE.csv',\n",
      " '1': '/home/ec2-user/AnnEconForecast/data/UNRATE.csv',\n",
      " '2': '/home/ubuntu/AnnEconForecast/data/UNRATE.csv',\n",
      " '3': '/home/ec2-user/AnnEconForecast/data/DEXCAUS.csv'}\n",
      "Select Dataset >>> 1\n",
      "Dataset chosen: \n",
      "\t/home/ec2-user/AnnEconForecast/data/UNRATE.csv\n",
      "Name of configuration file to load >>> sample_config\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'core.training'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2feca4f02a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mconfig_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Name of configuration file to load >>> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"import core.training.configs.{config_name} as config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0matt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'core.training'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The default hyper-parameter searching program.\n",
    "This is a control script.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from typing import Dict, List\n",
    "\n",
    "import sys\n",
    "sys.path.append(\".../\")\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import constants\n",
    "from core.tools.metrics import *\n",
    "import core.tools.visualize as visualize\n",
    "from core.tools.time_series import *\n",
    "from core.tools.data_import import *\n",
    "import core.tools.rnn_prepare as rnn_prepare\n",
    "\n",
    "import core.models.stacked_lstm as stacked_lstm\n",
    "\n",
    "import hps_methods as hps_methods\n",
    "\n",
    "# data preparation phase.\n",
    "pprint(constants.DATA_DIR)\n",
    "choice = None\n",
    "while choice is None or choice not in constants.DATA_DIR.keys():\n",
    "    if choice is not None:\n",
    "        print(\"Invalid data location received, try again...\")\n",
    "    choice = input(\"Select Dataset >>> \")\n",
    "FILE_DIR = constants.DATA_DIR[choice]\n",
    "\n",
    "print(f\"Dataset chosen: \\n\\t{FILE_DIR}\")\n",
    "\n",
    "config_name = input(\"Name of configuration file to load >>> \")\n",
    "\n",
    "exec(f\"import core.training.configs.{config_name} as config\")\n",
    "\n",
    "for att in dir(config):\n",
    "    if att.endswith(\"_config\"):\n",
    "        print(f\"Loading: {att}\")\n",
    "        exec(f\"globals().update\")\n",
    "\n",
    "\n",
    "parameter_collection = hps_methods.gen_hparam_set(config.train_param)\n",
    "\n",
    "\n",
    "def individual_train(para) -> None:\n",
    "    prepared_df = rnn_prepare.prepare_dataset(\n",
    "        file_dir=FILE_DIR,\n",
    "        periods=PERIODS,\n",
    "        order=ORDER,\n",
    "        remove=None\n",
    "    )\n",
    "    (X_train, X_val, X_test,\n",
    "     y_train, y_val, y_test) = rnn_prepare.generate_splited_dataset(\n",
    "        raw=prepared_df,\n",
    "        train_ratio=0.8,\n",
    "        val_ratio=0.1,\n",
    "        lags=para[\"num_time_steps\"]\n",
    "    )\n",
    "    data_collection = {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_val\": X_val,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_val\": y_val,\n",
    "        \"y_test\": y_test\n",
    "    }\n",
    "\n",
    "    def checkpoints(z): return [\n",
    "        z*x for x in range(1, para[\"epochs\"] // z)] + [-1]\n",
    "    \n",
    "    (metrics_dict, predictions) = stacked_lstm.exec_core(\n",
    "        parameters=para,\n",
    "        data_collection=data_collection,\n",
    "        clip_grad=None,\n",
    "        prediction_checkpoints=checkpoints(\n",
    "            para[\"epochs\"] // 10\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = visualize.plot_checkpoints(predictions, y_test, \"test\")\n",
    "    plt.savefig(para[\"fig_path\"]+\"pred_records.svg\")\n",
    "\n",
    "\n",
    "for (i, para) in enumerate(parameter_collection):\n",
    "    print(f\"Control: executing [{i}]-th hyper-parameter searching session...\")\n",
    "    individual_train(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'constants'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8809bce54364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'constants'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
