{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 715 µs\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.extend([\"../\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 196 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from core.tools.data_import import *\n",
    "from core.tools.time_series import *\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EC2': '/home/ec2-user/code/EFANN/data/UNRATE.csv',\n",
      " 'MAC': '/Users/tianyudu/Documents/Academics/EconForecasting/EFANN/data/UNRATE.csv'}\n",
      "Select Directory EC2\n",
      "time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(UNRATE_DIR)\n",
    "file_dir = input(\"Select Directory \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.    \n",
      "\tIndex type: datetime64[ns]    \n",
      "\tData type: float64\n",
      "25 (2.94%) observations with Nan are dropped.\n",
      "time: 27.6 ms\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset(UNRATE_DIR[\"EC2\"])\n",
    "df_d1 = differencing(df, periods=1, order=1)\n",
    "\n",
    "lags = list(range(1, 25))\n",
    "X_FEATURES = len(lags)\n",
    "X_raw, y_raw = gen_supervised(df_d1, predictors=lags)\n",
    "X_raw, y_raw = clean_nan(X_raw, y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.28 ms\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test,\n",
    " y_train, y_test) = train_test_split(\n",
    "    X_raw, y_raw,\n",
    "    test_size=0.2,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "(X_train, X_val,\n",
    " y_train, y_val) = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.1 ms\n"
     ]
    }
   ],
   "source": [
    "# Expand dimension so it fits the RNN input place holder.\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "X_val = np.expand_dims(X_val, axis=2)\n",
    "\n",
    "y_train = np.expand_dims(y_train, axis=1)\n",
    "y_test = np.expand_dims(y_test, axis=1)\n",
    "y_val = np.expand_dims(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing set generated,\n",
      "X_train shape: (528, 24, 1)\n",
      "y_train shape: (528, 1, 1)\n",
      "X_test shape: (165, 24, 1)\n",
      "y_test shape: (165, 1, 1)\n",
      "X_validation shape: (132, 24, 1)\n",
      "y_validation shape: (132, 1, 1)\n",
      "time: 581 µs\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training and testing set generated,\\\n",
    "\\nX_train shape: {X_train.shape}\\\n",
    "\\ny_train shape: {y_train.shape}\\\n",
    "\\nX_test shape: {X_test.shape}\\\n",
    "\\ny_test shape: {y_test.shape}\\\n",
    "\\nX_validation shape: {X_val.shape}\\\n",
    "\\ny_validation shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 647 µs\n"
     ]
    }
   ],
   "source": [
    "num_time_steps = len(lags)\n",
    "# Number of series used to predict. (including concurrent)\n",
    "num_inputs = 1\n",
    "num_neurons = 256\n",
    "# Number of output series\n",
    "num_outputs = 1\n",
    "learning_rate = 0.001\n",
    "num_iter = 500\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.05 ms\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# setting up\n",
    "X = tf.placeholder(\n",
    "    tf.float32,\n",
    "    [None, num_time_steps, num_inputs],\n",
    "    name=\"Input_placeholder\")\n",
    "y = tf.placeholder(\n",
    "    tf.float32,\n",
    "    [None, 1, num_outputs],\n",
    "    name=\"Output_placeholder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 102 ms\n"
     ]
    }
   ],
   "source": [
    "# Build RNN.\n",
    "cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "    tf.contrib.rnn.LSTMCell(\n",
    "        num_units=num_neurons,\n",
    "        activation=tf.nn.relu),\n",
    "    output_size=num_outputs\n",
    ")\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 369 ms\n"
     ]
    }
   ],
   "source": [
    "# Operators\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [0], Training MSE 0.0451169; Validation MSE 0.0180673\n",
      "Iteration [10], Training MSE 0.0418303; Validation MSE 0.0186854\n",
      "Iteration [20], Training MSE 0.0385369; Validation MSE 0.0175885\n",
      "Iteration [30], Training MSE 0.0374411; Validation MSE 0.0178896\n",
      "Iteration [40], Training MSE 0.0368782; Validation MSE 0.0177379\n",
      "Iteration [50], Training MSE 0.0364643; Validation MSE 0.0177285\n",
      "Iteration [60], Training MSE 0.0361065; Validation MSE 0.0175871\n"
     ]
    }
   ],
   "source": [
    "hist = {\"train\": [], \"val\": []}\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(num_iter):\n",
    "        sess.run(train,\n",
    "                 feed_dict={X: X_train, y: y_train})\n",
    "        if e % 10 == 0:\n",
    "            train_mse = loss.eval(feed_dict={X: X_train, y: y_train})\n",
    "            val_mse = loss.eval(feed_dict={X: X_val, y: y_val})\n",
    "            hist[\"train\"].append(train_mse)\n",
    "            hist[\"val\"].append(val_mse)\n",
    "            print(f\"Iteration [{e}], Training MSE {train_mse:0.7f}; Validation MSE {val_mse:0.7f}\")\n",
    "            \n",
    "    pred_train = sess.run(outputs, feed_dict={X: X_train})\n",
    "    pred_val = sess.run(outputs, feed_dict={X: X_val})\n",
    "    pred_test = sess.run(outputs, feed_dict={X: X_test})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = lambda x: np.squeeze(x[:, -1: ])\n",
    "pred_train = clean(pred_train)\n",
    "pred_val = clean(pred_val)\n",
    "pred_test = clean(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.figure(figsize=(32,16))\n",
    "plt.plot(pred_test)\n",
    "plt.plot(np.squeeze(y_test))\n",
    "plt.legend([\"Test Prediction\", \"Test Actual\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.figure(figsize=(32,16))\n",
    "plt.plot(pred_val)\n",
    "plt.plot(np.squeeze(y_val))\n",
    "plt.legend([\"Validation Prediction\", \"Validation Actual\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(np.log(hist[\"train\"]))\n",
    "plt.plot(np.log(hist[\"val\"]))\n",
    "plt.legend([\"Log Training Loss\", \"Log Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
