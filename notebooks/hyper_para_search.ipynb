{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.24.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This notebook is used for model hyper-parameter searching.\n",
    "Also, if this can also be used as a baseline training script.\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# If this notebook file is not placed under in /notebook/ directory,\n",
    "# adding directory \"../\" might not correly add the project directory.\n",
    "# If adding \"../\" does not solve the importing problem, we need to setup \n",
    "# the directory mannually.\n",
    "try:\n",
    "    import constants\n",
    "except ModuleNotFoundError:\n",
    "    core_dir = input(\"Directory of core files >>> \")\n",
    "    if not core_dir.endswith(\"/\"):\n",
    "        core_dir += \"/\"\n",
    "    sys.path.append(core_dir)\n",
    "    import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tools.metrics import *\n",
    "import core.tools.visualize as visualize\n",
    "from core.tools.time_series import *\n",
    "from core.tools.data_import import *\n",
    "import core.tools.rnn_prepare as rnn_prepare\n",
    "import core.tools.param_set_generator as param_set_generator\n",
    "\n",
    "import core.models.stacked_lstm as stacked_lstm\n",
    "\n",
    "import core.training.hps_methods as hps_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': '/Users/tianyudu/Documents/Academics/EconForecasting/AnnEconForecast/data/UNRATE.csv',\n",
      " 'b': '/home/ec2-user/AnnEconForecast/data/UNRATE.csv',\n",
      " 'c': '/home/ec2-user/AnnEconForecast/data/DEXCAUS.csv'}\n",
      "Dataset chosen: /Users/tianyudu/Documents/Academics/EconForecasting/AnnEconForecast/data/UNRATE.csv\n",
      "Avaiable configuration files found: \n",
      "\tsample_config.py\n",
      "\tec2_config.py\n",
      "\tmac_config.py\n"
     ]
    }
   ],
   "source": [
    "# data preparation phase.\n",
    "pprint(constants.DATA_DIR)\n",
    "# choice = None\n",
    "# while choice is None or choice not in constants.DATA_DIR.keys():\n",
    "#     if choice is not None:\n",
    "#         print(\"Invalid data location received, try again...\")\n",
    "#     choice = input(\"Select Dataset >>> \")\n",
    "choice = \"a\"\n",
    "\n",
    "FILE_DIR = constants.DATA_DIR[choice]\n",
    "\n",
    "print(f\"Dataset chosen: {FILE_DIR}\")\n",
    "\n",
    "print(\"Avaiable configuration files found: \")\n",
    "for cf in os.listdir(\"../hps_configs\"):\n",
    "    if cf.endswith(\"config.py\"):\n",
    "        print(\"\\t\" + cf)\n",
    "\n",
    "# config_name = input(\"Select config file >>> \")\n",
    "config_name = \"mac_config\"\n",
    "if config_name.endswith(\".py\"):\n",
    "    config_name = config_name[:-3]\n",
    "\n",
    "exec(f\"import hps_configs.{config_name} as config\")\n",
    "\n",
    "# print(\"Reading configuration file...\")\n",
    "# for att in dir(config):\n",
    "#     if att.endswith(\"_config\"):\n",
    "#         print(f\"\\tLoading: {att}\")\n",
    "#         exec(f\"globals().update(config.{att})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameter sets generated: 12\n"
     ]
    }
   ],
   "source": [
    "parameter_collection = param_set_generator.gen_hparam_set(config.main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LAGS': 6,\n",
      " 'ORDER': 1,\n",
      " 'PERIODS': 1,\n",
      " 'TRAIN_RATIO': 0.8,\n",
      " 'VAL_RATIO': 0.1,\n",
      " 'clip_grad': None,\n",
      " 'epochs': 150,\n",
      " 'fig_path': '/Users/tianyudu/Desktop/sample_model/model_figs/LAGS=6-num_time_steps=6-num_neurons=(32, '\n",
      "             '64)-learning_rate=0.1',\n",
      " 'hparam_str': 'LAGS=6-num_time_steps=6-num_neurons=(32, 64)-learning_rate=0.1',\n",
      " 'learning_rate': 0.1,\n",
      " 'model_path': '/Users/tianyudu/Desktop/sample_model/saved_models/LAGS=6-num_time_steps=6-num_neurons=(32, '\n",
      "               '64)-learning_rate=0.1',\n",
      " 'num_inputs': 1,\n",
      " 'num_neurons': (32, 64),\n",
      " 'num_outputs': 1,\n",
      " 'num_time_steps': 6,\n",
      " 'report_periods': 10,\n",
      " 'tensorboard_dir': '/Users/tianyudu/Desktop/sample_model/tensorboard/LAGS=6-num_time_steps=6-num_neurons=(32, '\n",
      "                    '64)-learning_rate=0.1'}\n"
     ]
    }
   ],
   "source": [
    "pprint(parameter_collection[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Executing hyper-parameter searching session [0/11]...\n",
      "Session Config:\n",
      "\tLAGS=6\n",
      "\tnum_time_steps=6\n",
      "\tnum_neurons=(16, 32)\n",
      "\tlearning_rate=0.1\n",
      "Dataset loaded.    \n",
      "\tIndex type: datetime64[ns]    \n",
      "\tData type: float64\n",
      "StandardScaler applied, scaling based on the first 679 observations.\n",
      "Total 842 observations generated.\n",
      "Note: shape format: (num_obs, time_steps, num_inputs/outputs)\n",
      "X shape = (842, 6, 1), y shape = (842, 1, 1)\n",
      "Training and testing set generated,        \n",
      "X_train shape: (672, 6, 1)        \n",
      "y_train shape: (672, 1)        \n",
      "X_test shape: (85, 6, 1)        \n",
      "y_test shape: (85, 1)        \n",
      "X_validation shape: (85, 6, 1)        \n",
      "y_validation shape: (85, 1)\n",
      "Saving the model...\n",
      "Time taken for [150] epochs:  0:00:02.760966\n",
      "Final result:\n",
      "Loss Summary:\n",
      "\tmae=0.571056604385376\n",
      "\tmse=0.5170398354530334\n",
      "\trmse=0.7190548181533813\n",
      "\tmape=6.909898281097412\n",
      "Time taken for session [0]: 0:00:07.173900.\n",
      "================================================================\n",
      "Executing hyper-parameter searching session [1/11]...\n",
      "Session Config:\n",
      "\tLAGS=6\n",
      "\tnum_time_steps=6\n",
      "\tnum_neurons=(32, 64)\n",
      "\tlearning_rate=0.1\n",
      "Dataset loaded.    \n",
      "\tIndex type: datetime64[ns]    \n",
      "\tData type: float64\n",
      "StandardScaler applied, scaling based on the first 679 observations.\n",
      "Total 842 observations generated.\n",
      "Note: shape format: (num_obs, time_steps, num_inputs/outputs)\n",
      "X shape = (842, 6, 1), y shape = (842, 1, 1)\n",
      "Training and testing set generated,        \n",
      "X_train shape: (672, 6, 1)        \n",
      "y_train shape: (672, 1)        \n",
      "X_test shape: (85, 6, 1)        \n",
      "y_test shape: (85, 1)        \n",
      "X_validation shape: (85, 6, 1)        \n",
      "y_validation shape: (85, 1)\n",
      "Saving the model...\n",
      "Time taken for [150] epochs:  0:00:04.931492\n",
      "Final result:\n",
      "Loss Summary:\n",
      "\tmae=0.5047174096107483\n",
      "\tmse=0.38124725222587585\n",
      "\trmse=0.6174522042274475\n",
      "\tmape=5.878105640411377\n",
      "Time taken for session [1]: 0:00:09.115318.\n",
      "================================================================\n",
      "Executing hyper-parameter searching session [2/11]...\n",
      "Session Config:\n",
      "\tLAGS=6\n",
      "\tnum_time_steps=6\n",
      "\tnum_neurons=(64, 64, 128)\n",
      "\tlearning_rate=0.1\n",
      "Dataset loaded.    \n",
      "\tIndex type: datetime64[ns]    \n",
      "\tData type: float64\n",
      "StandardScaler applied, scaling based on the first 679 observations.\n",
      "Total 842 observations generated.\n",
      "Note: shape format: (num_obs, time_steps, num_inputs/outputs)\n",
      "X shape = (842, 6, 1), y shape = (842, 1, 1)\n",
      "Training and testing set generated,        \n",
      "X_train shape: (672, 6, 1)        \n",
      "y_train shape: (672, 1)        \n",
      "X_test shape: (85, 6, 1)        \n",
      "y_test shape: (85, 1)        \n",
      "X_validation shape: (85, 6, 1)        \n",
      "y_validation shape: (85, 1)\n",
      "Saving the model...\n",
      "Time taken for [150] epochs:  0:00:13.605229\n",
      "Final result:\n",
      "Loss Summary:\n",
      "\tmae=0.4937587082386017\n",
      "\tmse=0.40899962186813354\n",
      "\trmse=0.6395307779312134\n",
      "\tmape=2.9738547801971436\n",
      "Time taken for session [2]: 0:00:17.914109.\n",
      "================================================================\n",
      "Executing hyper-parameter searching session [3/11]...\n",
      "Session Config:\n",
      "\tLAGS=6\n",
      "\tnum_time_steps=12\n",
      "\tnum_neurons=(16, 32)\n",
      "\tlearning_rate=0.1\n",
      "Dataset loaded.    \n",
      "\tIndex type: datetime64[ns]    \n",
      "\tData type: float64\n",
      "StandardScaler applied, scaling based on the first 679 observations.\n",
      "Total 842 observations generated.\n",
      "Note: shape format: (num_obs, time_steps, num_inputs/outputs)\n",
      "X shape = (842, 6, 1), y shape = (842, 1, 1)\n",
      "Training and testing set generated,        \n",
      "X_train shape: (672, 6, 1)        \n",
      "y_train shape: (672, 1)        \n",
      "X_test shape: (85, 6, 1)        \n",
      "y_test shape: (85, 1)        \n",
      "X_validation shape: (85, 6, 1)        \n",
      "y_validation shape: (85, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (672, 6, 1) for Tensor 'DATA_FEED/FEATURE:0', which has shape '(?, 12, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-198d05cb11d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mparam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mexec_core\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacked_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_core\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mfile_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFILE_DIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Time taken for session [{i}]: {str(datetime.now() - start)}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Academics/EconForecasting/AnnEconForecast/core/training/hps_methods.py\u001b[0m in \u001b[0;36mindividual_train\u001b[0;34m(param, exec_core, file_dir)\u001b[0m\n\u001b[1;32m     53\u001b[0m         prediction_checkpoints=checkpoints(\n\u001b[1;32m     54\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         ) + [-1]\n\u001b[0m\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Academics/EconForecasting/AnnEconForecast/core/models/stacked_lstm.py\u001b[0m in \u001b[0;36mexec_core\u001b[0;34m(param, data, prediction_checkpoints, verbose)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m#     sess.run(train, feed_dict={X: X_batch, y: y_batch})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X_train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y_train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"report_periods\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (672, 6, 1) for Tensor 'DATA_FEED/FEATURE:0', which has shape '(?, 12, 1)'"
     ]
    }
   ],
   "source": [
    "for (i, param) in enumerate(parameter_collection):\n",
    "    print(\"================================================================\")\n",
    "    print(f\"Executing hyper-parameter searching session [{i}/{len(parameter_collection) - 1}]...\")\n",
    "    print(\"Session Config:\\n\\t\" + param[\"hparam_str\"].replace(\"-\", \"\\n\\t\"))\n",
    "    start = datetime.now()\n",
    "    hps_methods.individual_train(\n",
    "        param=param,\n",
    "        exec_core=stacked_lstm.exec_core,\n",
    "        file_dir=FILE_DIR\n",
    "    )\n",
    "    print(f\"Time taken for session [{i}]: {str(datetime.now() - start)}.\")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
