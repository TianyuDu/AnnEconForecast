{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")\n",
    "import core.tools.json_rec as json_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn-dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTROL PANEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: ./saved/2019-01-07_02:01:27\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: './saved/2019-01-07_02:01:27'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fb2ec350a6a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPATH_COL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./saved/{now}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_COL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m params = dict(\n\u001b[1;32m      4\u001b[0m     \u001b[0mCOL_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"UNRATE\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AnnEconForecast/standalone_dev/tools.py\u001b[0m in \u001b[0;36mmkdirs\u001b[0;34m(base)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating directory: {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './saved/2019-01-07_02:01:27'"
     ]
    }
   ],
   "source": [
    "PATH_COL = tools.mkdirs(f\"./saved/{now}\")\n",
    "pprint(PATH_COL)\n",
    "PARAMS = dict(\n",
    "    COL_NAME = \"UNRATE\",\n",
    "    P = 6,\n",
    "    NUM_TIME_STEPS = 6,\n",
    "    D = 1,\n",
    "    Q = None,\n",
    "    NUM_INPUTS = 1,\n",
    "    NUM_OUTPUTS = 1,\n",
    "    # Training Config\n",
    "    RNN_NEURONS = [128, 256, 256],\n",
    "    LR = 0.01,\n",
    "    EPOCHS = 1000,\n",
    "    CELL_TYPE = \"LSTM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals().update(PATH_COL)\n",
    "globals().update(PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_writer = json_rec.ParamWriter(file_dir=PATH_COL[\"BASE_PATH\"] + \"/params.json\")\n",
    "param_writer.write(PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/UNRATE.csv\", index_col=0, parse_dates=True)\n",
    "# df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "df.columns = [COL_NAME]\n",
    "print(df.dtypes)\n",
    "df.head()\n",
    "# month_df = df.resample(\"M\").mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = df.diff()  #  Take the first order differenced.\n",
    "diff.dropna(inplace=True)\n",
    "slp = tools.gen_slp_sequential(diff, num_time_steps=P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, ts = tools.format_instances(slp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train, ts_train,\n",
    "X_val, y_val, ts_val,\n",
    "X_test, y_test, ts_test) = tools.split_dataset(X, y, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(2, 1, 1)\n",
    "rcParams[\"figure.figsize\"] = (32, 16)\n",
    "plt.title(\"Observed Series\")\n",
    "plt.plot(ts_train, df[COL_NAME][ts_train], label=\"train\")\n",
    "plt.plot(ts_val, df[COL_NAME][ts_val], label=\"val\")\n",
    "plt.plot(ts_test, df[COL_NAME][ts_test], label=\"test\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "rcParams[\"figure.figsize\"] = (32, 16)\n",
    "plt.title(\"First Order Differenced\")\n",
    "plt.plot(ts_train, y_train[:, -1, :], label=\"train\")\n",
    "plt.plot(ts_val, y_val[:, -1, :], label=\"val\")\n",
    "plt.plot(ts_test, y_test[:, -1, :], label=\"test\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(PATH_COL[\"FIG_PATH\"] + \"/raw.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = plt.figure(figsize=(32,8))\n",
    "# plt.title(\"Log\")\n",
    "# plt.plot(ts_train, np.log(y_train[:, -1, :]), label=\"train\")\n",
    "# plt.plot(ts_val, np.log((y_val[:, -1, :])), label=\"val\")\n",
    "# plt.plot(ts_test, np.log(y_test[:, -1, :]), label=\"test\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Build LSTM Neural Net\n",
    "# Data IO Layers\n",
    "with tf.name_scope(\"DATA_IO\"):\n",
    "    X = tf.placeholder(\n",
    "        tf.float32,\n",
    "        [None, NUM_TIME_STEPS, NUM_INPUTS],\n",
    "        name=\"FEATURE\"\n",
    "    )\n",
    "    y = tf.placeholder(\n",
    "        tf.float32,\n",
    "        [None, NUM_TIME_STEPS, NUM_OUTPUTS],\n",
    "        name=\"LABEL\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent Structure.\n",
    "# with tf.name_scope(\"RECURRENT\"):\n",
    "if CELL_TYPE == \"GRU\":\n",
    "    cells = [\n",
    "        tf.nn.rnn_cell.GRUCell(\n",
    "            num_units=x,\n",
    "            name=f\"GRU_LAYER_{i}\")\n",
    "        for i, x in enumerate(RNN_NEURONS)\n",
    "    ]\n",
    "elif CELL_TYPE == \"LSTM\":\n",
    "    cells = [\n",
    "        tf.nn.rnn_cell.LSTMCell(\n",
    "            num_units=x,\n",
    "            name=f\"LSTM_LAYER_{i}\")\n",
    "        for i, x in enumerate(RNN_NEURONS)\n",
    "    ]\n",
    "else:\n",
    "    cells = [\n",
    "        Cell(\n",
    "            num_units=x,\n",
    "            name=f\"RNN_LAYER_{i}\")\n",
    "        for i, (Cell, x) in enumerate(zip(CellType, x))\n",
    "    ]\n",
    "\n",
    "multi_cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "outputs, state = tf.nn.dynamic_rnn(\n",
    "    cell=multi_cell,\n",
    "    inputs=X,\n",
    "    dtype=tf.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope(\"OUTPUT\"):\n",
    "reg_outputs = tf.layers.dense(\n",
    "    outputs,\n",
    "    NUM_OUTPUTS,\n",
    "    kernel_initializer=tf.random_normal_initializer(),\n",
    "    bias_initializer=tf.random_normal_initializer(),\n",
    "    activation=None,  # linear activation.\n",
    "    name=\"OUTPUT_DENSE\"\n",
    ")\n",
    "# W = tf.Variable(\n",
    "#     tf.random_normal(\n",
    "#     [RNN_NEURONS[-1], NUM_OUTPUTS],\n",
    "#     name=\"OUTPUT_WEIGHT\"\n",
    "#     )\n",
    "# )\n",
    "# b = tf.Variable(\n",
    "#     tf.random_normal(\n",
    "#     [NUM_OUTPUTS, 1],\n",
    "#     name=\"OUTPUT_BIAS\"\n",
    "#     )\n",
    "# )\n",
    "# reg_outputs = outputs @ W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"METRICS\"):\n",
    "#     loss = tf.losses.mean_squared_error(\n",
    "#         labels=y,\n",
    "#         predictions=reg_outputs,\n",
    "#     )\n",
    "    \n",
    "    # Redundent losses to evaluate and ensure the correctness of\n",
    "    # built-in losses function.\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.square(y - reg_outputs),\n",
    "        name=\"Red_MSE\",\n",
    "        axis=None\n",
    "    )\n",
    "    tf.summary.scalar(\"MSE\", loss)\n",
    "#     tf.summary.scalar(\"Red_MSE\", loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"OPTIMIZER\"):\n",
    "    optimizer = tf.train.AdamOptimizer(\n",
    "        learning_rate=LR,\n",
    "        name=\"OPTIMIZER\"\n",
    "    )\n",
    "#     gvs = optimizer.compute_gradients(loss)\n",
    "#     capped_gvs = [\n",
    "#         (tf.clip_by_value(\n",
    "#             grad, -1.0, 1.0), var)\n",
    "#         for grad, var in gvs\n",
    "#     ]\n",
    "#     train = optimizer.apply_gradients(capped_gvs)\n",
    "    train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(TB_PATH + \"/train\")\n",
    "    val_writer = tf.summary.FileWriter(TB_PATH + \"/validation\")\n",
    "    train_writer.add_graph(sess.graph)\n",
    "    for e in range(EPOCHS):\n",
    "#         tools.progbar(e+1, EPOCHS, 30)\n",
    "        sess.run(\n",
    "            train,\n",
    "            feed_dict={X: X_train, y: y_train}\n",
    "        )\n",
    "        if e % (EPOCHS // 10) == 0:\n",
    "            train_mse = loss.eval(feed_dict={X: X_train, y: y_train})\n",
    "            val_mse = loss.eval(feed_dict={X: X_val, y: y_val})\n",
    "            print(f\"Epoch={e}: train_MSE={train_mse}, val_MSE={val_mse}\")\n",
    "    \n",
    "        if e % 5 == 0:\n",
    "            tsum = sess.run(\n",
    "                merged_summary,\n",
    "                feed_dict={X: X_train, y: y_train}\n",
    "            )\n",
    "            vsum = sess.run(\n",
    "                merged_summary,\n",
    "                feed_dict={X: X_val, y: y_val}\n",
    "            )\n",
    "            train_writer.add_summary(tsum, e)\n",
    "            val_writer.add_summary(vsum, e)\n",
    "            \n",
    "    make_prediction = lambda data: sess.run(reg_outputs, feed_dict={X: data})\n",
    "    pred_train = make_prediction(X_train)\n",
    "    pred_val = make_prediction(X_val)\n",
    "    pred_test = make_prediction(X_test)\n",
    "print(f\"Time taken: {datetime.datetime.now() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_last = lambda pred_combo: np.squeeze([x[-1] for x in pred_combo])\n",
    "# NOTE: dfp stands for DataFrame of Prediction\n",
    "dfp_train = pd.DataFrame(data=extract_last(pred_train), index=ts_train)\n",
    "dfp_val = pd.DataFrame(data=extract_last(pred_val), index=ts_val)\n",
    "dfp_test = pd.DataFrame(data=extract_last(pred_test), index=ts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_diff = pd.concat([dfp_train, dfp_val, dfp_test])\n",
    "pred_diff.columns = [COL_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_raw = tools.inv_diff(pred_diff, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Raw ====\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "rcParams[\"figure.figsize\"] = (16, 8)\n",
    "plt.title(\"Ground truth versus Prediction on Raw Series\")\n",
    "plt.plot(df, label=\"Observed\", alpha=.6)\n",
    "plt.plot(pred_raw, label=\"Prediction\", alpha=.6)\n",
    "\n",
    "plt.axvline(x=diff.index[len(X_train)+1], color=\"grey\", alpha=.4, label=\"train-val boundary\")\n",
    "plt.axvline(x=diff.index[-len(X_test)+1], color=\"grey\", alpha=.4, label=\"val-test boundary\")\n",
    "plt.grid(True)\n",
    "\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"UNRATE\")\n",
    "plt.legend()\n",
    "\n",
    "# ==== First order differenced ====\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "rcParams[\"figure.figsize\"] = (16, 8)\n",
    "plt.title(\"Ground truth versus Prediction on First Order Differenced\")\n",
    "plt.plot(diff, label=\"Observed(Ground Truth)\", color=\"grey\", alpha=.7)\n",
    "plt.plot(dfp_train, label=\"Train\", alpha=.7)\n",
    "plt.plot(dfp_val, label=\"Validation\", alpha=.7)\n",
    "plt.plot(dfp_test, label=\"Test\", alpha=.7)\n",
    "plt.legend()\n",
    "\n",
    "ax2.set_xlabel(\"Date\")\n",
    "ax2.set_ylabel(\"Change in UNRATE\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(PATH_COL[\"FIG_PATH\"] + \"/prediction.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
