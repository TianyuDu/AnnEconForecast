{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.extend([\"../\"])\n",
    "from core.tools.data_import import *\n",
    "from core.tools.time_series import *\n",
    "from core.tools.visualize import *\n",
    "from core.models.baseline_rnn import *\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing Parameters\n",
    "PERIODS = 1\n",
    "ORDER = 1\n",
    "LAGS = 90\n",
    "\n",
    "df = load_dataset(\n",
    "    \"/Users/tianyudu/Documents/Academics/EconForecasting/AnnEconForecast/data/DEXCAUS.csv\")\n",
    "prepared_df = differencing(df, periods=PERIODS, order=ORDER)\n",
    "prepared_df.head()\n",
    "prepared_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.9\n",
    "# Normalize the sequence\n",
    "scaler = StandardScaler().fit(prepared_df[:int(TRAIN_RATIO*len(prepared_df))].values)\n",
    "prepared_df[\"DEXCAUS_period1_order1\"] = scaler.transform(prepared_df.values)\n",
    "\n",
    "X_raw, y_raw = gen_supervised_sequence(\n",
    "    prepared_df, LAGS, prepared_df.columns[0], sequential_label=False)\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(\n",
    "    X_raw, y_raw,\n",
    "    test_size=1 - TRAIN_RATIO,\n",
    "    shuffle=False)\n",
    "\n",
    "(X_train, X_val, y_train, y_val) = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = lambda x: x.reshape(-1, 1)\n",
    "y_train = op(y_train)\n",
    "y_test = op(y_test)\n",
    "y_val = op(y_val)\n",
    "\n",
    "print(f\"Training and testing set generated,\\\n",
    "\\nX_train shape: {X_train.shape}\\\n",
    "\\ny_train shape: {y_train.shape}\\\n",
    "\\nX_test shape: {X_test.shape}\\\n",
    "\\ny_test shape: {y_test.shape}\\\n",
    "\\nX_validation shape: {X_val.shape}\\\n",
    "\\ny_validation shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "num_time_steps = LAGS\n",
    "# Number of series used to predict. (including concurrent)\n",
    "num_inputs = 1\n",
    "num_outputs = 1\n",
    "num_neurons = 64\n",
    "# Number of output series\n",
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "# Training Settings\n",
    "report_periods = epochs // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, num_time_steps, num_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, num_outputs])\n",
    "\n",
    "cell = tf.contrib.rnn.LSTMCell(\n",
    "    num_units=num_neurons, activation=tf.nn.relu)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "stacked_output = tf.reshape(rnn_outputs, [-1, num_time_steps * num_neurons])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([num_time_steps * num_neurons, 1]), dtype=tf.float32)\n",
    "b = tf.Variable(tf.random_normal([1]), dtype=tf.float32)\n",
    "\n",
    "pred = tf.add(tf.matmul(stacked_output, W), b)\n",
    "\n",
    "# pred = tf.layers.dense(stacked_output, 1)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y, pred)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = {\"train\": [], \"val\": []}\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(500):\n",
    "        sess.run(train, feed_dict={X: X_train, y: y_train})\n",
    "        train_mse = loss.eval(feed_dict={X: X_train, y: y_train})\n",
    "        val_mse = loss.eval(feed_dict={X: X_val, y: y_val})\n",
    "        hist[\"train\"].append(train_mse)\n",
    "        hist[\"val\"].append(val_mse)\n",
    "        if e % report_periods == 0:\n",
    "            print(\n",
    "                f\"\\nIteration [{e}], Training MSE {train_mse:0.7f}; Validation MSE {val_mse:0.7f}\")\n",
    "\n",
    "    p_train = pred.eval(feed_dict={X: X_train})\n",
    "    p_test = pred.eval(feed_dict={X: X_test})\n",
    "    p_val = pred.eval(feed_dict={X: X_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-98d220777818>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Training Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Training Actual\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p_train' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2304x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "plt.figure(figsize=(32, 16))\n",
    "plt.plot(p_train.reshape(-1, 1), alpha=0.6)\n",
    "plt.plot(y_train.reshape(-1, 1), alpha=0.6)\n",
    "plt.legend([\"Training Prediction\", \"Training Actual\"])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n",
    "plt.figure(figsize=(32, 16))\n",
    "plt.plot(p_test.reshape(-1, 1), alpha=0.6)\n",
    "plt.plot(y_test.reshape(-1, 1), alpha=0.6)\n",
    "plt.legend([\"Testing Prediction\", \"Testing Actual\"])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n",
    "plt.figure(size=(32, 16))\n",
    "plt.plot(np.log(hist[\"train\"]))\n",
    "plt.plot(np.log(hist[\"val\"]))\n",
    "plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
