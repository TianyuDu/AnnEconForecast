print("abc")
print("Hello World")
install.packages("rattle")
qnorm(0.95)
print(qnorm(0.95),digits=100)
print(qnorm(0.95),digits=10)
print(qnorm(0.95),digits=90)
print(qnorm(0.95),digits=32)
print(qnorm(0.95),digits=16)
par(cex=0.8)
plot(AirPassengers,type="o", main="Monthly Airline Passenger Numbers 1949-1960")
grid()
qnorm(0.87)
pnorm(0.87)
pnorm(2.449)
pnorm(2.18218)
1-pnorm(2.18218)
install.packages(c("backports", "car", "carData", "caTools", "class", "cli", "codetools", "data.table", "digest", "dplyr", "e1071", "evaluate", "foreign", "ggplot2", "glue", "haven", "jsonlite", "knitr", "lattice", "lme4", "maptools", "markdown", "MASS", "Matrix", "mgcv", "mime", "nloptr", "packrat", "pillar", "pkgconfig", "psych", "quantreg", "R6", "Rcpp", "RcppArmadillo", "RcppEigen", "RCurl", "readr", "readxl", "rio", "RJSONIO", "rlang", "rmarkdown", "rpart.plot", "rsconnect", "rstudioapi", "scales", "stringi", "survival", "tibble", "tidyr", "tidyselect", "tinytex", "tseries", "TTR", "XML", "xts", "yaml", "zoo"))
z <- c([1,2,3,])
z <- c([1,2,3])
z <- c({1,2,3})
z <- c(1,2,3)
z[0]
z[1]
z[2]
z <- c(4,2,3)
z[0]
z[1]
z[2]
z[4]
libraryï¼ˆfpp2)
library(fpp2)
y <- ts(c(123, 39, 78, 52, 110), start=2012)
y <- ts(c(123, 39, 78, 52, 110), start=2012, frequency=12)
y
y <- ts(c(123, 39, 78, 52, 110), start=2012, frequency=1)
y
y <- ts(c(123, 39, 78, 52, 110), start=2012)
y
y <- ts(c(123, 39, 78, 52, 110), start=2012, frequency=365)
y
y <- ts(c(123, 39, 78, 52, 110), start=2012, frequency=12)
y
autoplot(melsyd[, "Economy.Class"]) +
ggtitle("Economy class passengers: Melbourne-Sydney") +
xlab("Year") +
ylab("Thousands"
)
beer2 <- window(ausbeer, start=1992)
gglagplot(beer2)
ggseasonplot(a10, polar=True) +
ylab("$million")
ggseasonplot(a10, polar=TRUE) +
ylab("$million")
beer2
gglagplot(ausbeer)
ausbeer
gglagplot(beer2)
aelec <- window(elec, start=1980)
autoplot(aelec) + xlab("Year") + ylab("GWh")
ggAcf(aelec, lag=48)
y <- ts(rnorm(50))
autoplot(y)
ggAcf(y)
gold
install.packages(quantmod)
install.packages("quantmod")
install.packages("quantmod")
z = getSymbols('CPIAUCNS',src='FRED')
library(quantmod)
z = getSymbols('CPIAUCNS',src='FRED')
z
getSymbols('CPIAUCNS',src='FRED')
CPIAUCNS
library(fpp2)
library(stats)
autoplot(CPIAUCNS)
getSymbols("PCEC96",src="FRED")
getSymbols("DSPIC96", src="FRED")
install.packages("import-fred")
install.packages("fredr")
fredr_set_key("4e615d1efa9b5b5297720fd88667e7cd")
fredr_set_key("4e615d1efa9b5b5297720fd88667e7cd")
library(fredr)
fredr_set_key("4e615d1efa9b5b5297720fd88667e7cd")
fredr("UNRATE ")
fredr("UNRATE")
t <- ts(fredr("UNRATE"))
t
t <- ts(fredr("UNRATE"), frequency = 12)
t
t <- fredr("UNRATE")
t
t$date
fredr(
series_id = "UNRATE",
observation_start = as.Date("1990-01-01")
)
library(fpp2)
library(stats)
library(fredr)
fredr_set_key("4e615d1efa9b5b5297720fd88667e7cd")
fredr(
series_id = "UNRATE",
observation_start = as.Date("1990-01-01")
)
t <- fredr(
series_id = "UNRATE",
observation_start = as.Date("1990-01-01")
)
autoplot(t)
ggplot(t$value, t$date)
t2 <- ts(t)
t2
ggplot(t$value)
auto(t$value)
autoplot(t$value)
help invnorm
help qnorm()
help qnorm
help(qnorm)
qnorm(0)
znorm(0)
dnorm(0)
1/sqrt(2*pi)
help(rnorm)
rnorm(0.5)
rnorm(0.05)
pnorm(0.5)
pnorm(0)
pnorm(-1.96)
pnorm(-1.65)
-1.65 / pnorm(0.05)
pnorm(-1.65)
-1.65 / pnorm(-1.65)
pnorm(-1.65)
dnorm(-1.65) / 0.05
norm(0.05)
qnorm(0.05)
dnorm(qnorm(0.05))/0.05
pnorm(0)
rnorm(100)
c([0] * 10)
c([0], 10)
rep(0, 3)
rep(0, 10)
help(qqplot)
qnorm(0.05)
sort(c([1,2,3]))
sort(c(1,2,3))
sort(c(1,2,3,1))
plot(cars)
data <- read.csv(file="/Users/tianyudu/Documents/UToronto/Course/ECO374/SWA/VIX.csv", header=TRUE, sep=",")
data <- na.omit(data)
xtsdata <- xts(data[c("Close")], order.by=anytime(data$Date))
library(stats)
library(anytime)
library(xts)
library(fGarch)
library(aTSA)
remove(list=ls())
setwd("/Users/tianyudu/Documents/UToronto/Course/ECO374/SWA")
data <- read.csv(file="/Users/tianyudu/Documents/UToronto/Course/ECO374/SWA/VIX.csv", header=TRUE, sep=",")
data <- na.omit(data)
xtsdata <- xts(data[c("Close")], order.by=anytime(data$Date))
adf.test(as.matrix(xtsdata))
library(stats)
library(anytime)
library(xts)
library(fGarch)
library(aTSA)
remove(list=ls())
setwd("/Users/tianyudu/Documents/UToronto/Course/ECO374/SWA")
data <- read.csv(file="/Users/tianyudu/Documents/UToronto/Course/ECO374/SWA/VIX.csv", header=TRUE, sep=",")
data <- na.omit(data)
xtsdata <- xts(data[c("Close")], order.by=anytime(data$Date))
plot.xts(xtsdata$Close, main="CBOE Volatility Index")
adf.test(as.matrix(xtsdata))
maxlag <- 15
ACF <- acf(x=as.matrix(xtsdata), lag.max=15, plot=FALSE)
PACF <- pacf(x=as.matrix(xtsdata), log.max=15, plot=FALSE)
maxlag <- 15
ACF <- acf(x=as.matrix(xtsdata), lag.max=15, plot=FALSE)
PACF <- pacf(x=as.matrix(xtsdata), log.max=15, plot=FALSE)
plot(ACF, main="ACF")
plot(PACF, main="PACF")
maxlag <- 15
ACF <- acf(x=as.matrix(xtsdata), lag.max=15, plot=FALSE)
PACF <- pacf(x=as.matrix(xtsdata), log.max=15, plot=FALSE)
par(mfcol=c(1,2), mai=c(0.4, 0.4, 0.7, 0.1), cex.main=0.9)
plot(ACF, main="ACF")
plot(PACF, main="PACF")
help(PACF)
help(pacf)
maxlag <- 15
ACF <- acf(x=as.matrix(xtsdata), lag.max=15, plot=FALSE)
PACF <- pacf(x=as.matrix(xtsdata), log.max=15, plot=FALSE)
par(mfcol=c(1,2), mai=c(0.4, 0.4, 0.7, 0.1), cex.main=0.9)
plot(ACF, main="ACF")
plot(PACF, main="PACF")
GARCH <- garchFit(~arma(1,0)+garch(1,1), data=xtsdata$Close, trace=TRUE)
f <- predict(GARCH, plot=TRUE, n.ahead=10)
?lm
# May 17 2019
# Benchmark ARIMA for sunspot data.
# We use the basic sunspot time series data
library(fpp2)
library(ggfortify)
library(forecast)
library(stats)
library(aTSA)
library(lmtest)
setwd("/Users/tianyudu/Documents/Academics/EconForecasting/AnnEconForecast")
df <- read.csv("./data/sunspots.csv", header=TRUE, sep=",", col.names=c("Year", "Sunspots"))
ts_all <- ts(df$Sunspots,start=c(1700),frequency=1)
# Train and test spliting
train_size <- as.integer(0.8 * length(ts_all))
test_size <- length(ts_all) - train_size
ts_train <- head(ts_all, train_size)
ts_test <- tail(ts_all, test_size)
autoplot(ts_train) +
ggtitle("Number of sunspots") +
xlab("Year") +
ylab("Sunspot") +
theme(plot.title = element_text(size=8, face="bold"))
# Determine the d number.
ndiffs(ts_train)
# Inspect the transformed sequence
transformed <- diff(ts_train, lag=1, differences=1)
ACF <- Acf(transformed, plot=TRUE, lag.max=34) # q=1
PACF <-Pacf(transformed, plot=TRUE, lag.max=34) # p=8
autoplot(transformed) +
ggtitle("Differenced Series") +
xlab("Date") +
ylab("Transformed")
# Test stationarity
adf.test(transformed)
# Find the model minimizing AIC w/ correction.
auto.arima(ts_train, max.p=10, max.P=10, max.q=10, max.Q=10, max.d=3, max.D=3, trace=TRUE)
# ==== Fit and Evaluate the Model ====
model <- arima(ts_train, order=c(2,0,1))
res <- residuals(model)
mse <- mean(res**2)
rmse <- sqrt(mse)
err_abspec <- abs(res)/ts_train
mape <- mean(
err_abspec[err_abspec != Inf]
)
cat("MSE:", mse, "RMSE:", rmse, "MAPE:", mape)
coeftest(model)
# Simple forecast
fore <- forecast::forecast(model, h=1, level=c(99))
autoplot(fore)
# Rolling forecast
rf <- c()
for (i in c(1: test_size)){
# Refit model
model <- arima(
head(ts_all, train_size+i-1),
# To predict the first element of the test set, we use the whole training set.
# To predict the k-th element of the test set (i.e. train_size+k th element), use all previouse train_size+k-1 elements.
order=c(2,0,1)
)
# Produce one step forecast
f <- forecast::forecast(model, h=1, level=c(99))
rf <- c(rf, f$mean)  # Add rolling forecast.
}
ts_rf <- ts(rf, start=time(ts_test)[1])
combined <- cbind("Rolling Forecast"=ts_rf, "Actual"=ts_test)
autoplot(combined) +
ggtitle("One Step Rolling Forecasting on Test Set") +
xlab("Date") +
ylab("Sunspot")
# Performance Metrics
mse_test <- mean((ts_rf - ts_test) ** 2)
rmse_test <- sqrt(mse_test)
cat("Test MSE:", mse, "RMSE:", rmse)
d1 <- na.omit(diff(ts_all))
d1 ** 2
mean(d1 ** 2)
# Forecasting of naive preddictor, as a baseline model.
baseline_error <- mean(na.omit(diff(ts_test)))
cat(baseline_error)
# Forecasting of naive preddictor, as a baseline model.
baseline_error <- mean(na.omit(diff(ts_test)))
cat(baseline_error)
ts_test
diff(ts_test)
# Forecasting of naive preddictor, as a baseline model.
baseline_error <- mean(na.omit(diff(ts_test)) ** 2)
cat(baseline_error)
baseline_error <- mean(
na.omit(diff(ts_test)) ** 2
)
cat(baseline_error)
# Forecasting of naive preddictor, as a baseline model.
baseline_error <- mean(
diff(ts_test) ** 2
)
cat(baseline_error)
# May 17 2019
# Benchmark ARIMA for sunspot data.
# We use the basic sunspot time series data
library(fpp2)
library(ggfortify)
library(forecast)
library(stats)
library(aTSA)
library(lmtest)
setwd("/Users/tianyudu/Documents/Academics/EconForecasting/AnnEconForecast")
df <- read.csv("./data/sunspots.csv", header=TRUE, sep=",", col.names=c("Year", "Sunspots"))
ts_all <- ts(df$Sunspots,start=c(1700),frequency=1)
# Train and test spliting
train_size <- as.integer(0.8 * length(ts_all))
test_size <- length(ts_all) - train_size
ts_train <- head(ts_all, train_size)
ts_test <- tail(ts_all, test_size)
# Forecasting of naive preddictor, as a baseline model.
baseline_error <- mean(
diff(ts_test) ** 2
)
cat(baseline_error)
# ==== End ====
autoplot(ts_train) +
ggtitle("Number of sunspots") +
xlab("Year") +
ylab("Sunspot") +
theme(plot.title = element_text(size=8, face="bold"))
# Determine the d number.
ndiffs(ts_train)
# Inspect the transformed sequence
transformed <- diff(ts_train, lag=1, differences=1)
ACF <- Acf(transformed, plot=TRUE, lag.max=34) # q=1
PACF <-Pacf(transformed, plot=TRUE, lag.max=34) # p=8
autoplot(transformed) +
ggtitle("Differenced Series") +
xlab("Date") +
ylab("Transformed")
# Test stationarity
adf.test(transformed)
# Find the model minimizing AIC w/ correction.
auto.arima(ts_train, max.p=10, max.P=10, max.q=10, max.Q=10, max.d=3, max.D=3, trace=TRUE)
# ==== Fit and Evaluate the Model ====
model <- arima(ts_train, order=c(2,0,1))
res <- residuals(model)
mse <- mean(res**2)
rmse <- sqrt(mse)
err_abspec <- abs(res)/ts_train
mape <- mean(
err_abspec[err_abspec != Inf]
)
cat("MSE:", mse, "RMSE:", rmse, "MAPE:", mape)
coeftest(model)
# Simple forecast
fore <- forecast::forecast(model, h=1, level=c(99))
autoplot(fore)
# Rolling forecast
rf <- c()
for (i in c(1: test_size)){
# Refit model
model <- arima(
head(ts_all, train_size+i-1),
# To predict the first element of the test set, we use the whole training set.
# To predict the k-th element of the test set (i.e. train_size+k th element), use all previouse train_size+k-1 elements.
order=c(2,0,1)
)
# Produce one step forecast
f <- forecast::forecast(model, h=1, level=c(99))
rf <- c(rf, f$mean)  # Add rolling forecast.
}
ts_rf <- ts(rf, start=time(ts_test)[1])
combined <- cbind("Rolling Forecast"=ts_rf, "Actual"=ts_test)
autoplot(combined) +
ggtitle("One Step Rolling Forecasting on Test Set") +
xlab("Date") +
ylab("Sunspot")
# Performance Metrics
mse_test <- mean((ts_rf - ts_test) ** 2)
rmse_test <- sqrt(mse_test)
cat("Test MSE:", mse, "RMSE:", rmse)
