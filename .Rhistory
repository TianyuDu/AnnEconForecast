sort(c(1,2,3,1))
plot(cars)
data <- read.csv(file="/Users/tianyudu/Documents/UToronto/Course/ECO374/SWA/VIX.csv", header=TRUE, sep=",")
data <- na.omit(data)
xtsdata <- xts(data[c("Close")], order.by=anytime(data$Date))
library(stats)
library(anytime)
library(xts)
library(fGarch)
library(aTSA)
remove(list=ls())
setwd("/Users/tianyudu/Documents/UToronto/Course/ECO374/SWA")
data <- read.csv(file="/Users/tianyudu/Documents/UToronto/Course/ECO374/SWA/VIX.csv", header=TRUE, sep=",")
data <- na.omit(data)
xtsdata <- xts(data[c("Close")], order.by=anytime(data$Date))
adf.test(as.matrix(xtsdata))
library(stats)
library(anytime)
library(xts)
library(fGarch)
library(aTSA)
remove(list=ls())
setwd("/Users/tianyudu/Documents/UToronto/Course/ECO374/SWA")
data <- read.csv(file="/Users/tianyudu/Documents/UToronto/Course/ECO374/SWA/VIX.csv", header=TRUE, sep=",")
data <- na.omit(data)
xtsdata <- xts(data[c("Close")], order.by=anytime(data$Date))
plot.xts(xtsdata$Close, main="CBOE Volatility Index")
adf.test(as.matrix(xtsdata))
maxlag <- 15
ACF <- acf(x=as.matrix(xtsdata), lag.max=15, plot=FALSE)
PACF <- pacf(x=as.matrix(xtsdata), log.max=15, plot=FALSE)
maxlag <- 15
ACF <- acf(x=as.matrix(xtsdata), lag.max=15, plot=FALSE)
PACF <- pacf(x=as.matrix(xtsdata), log.max=15, plot=FALSE)
plot(ACF, main="ACF")
plot(PACF, main="PACF")
maxlag <- 15
ACF <- acf(x=as.matrix(xtsdata), lag.max=15, plot=FALSE)
PACF <- pacf(x=as.matrix(xtsdata), log.max=15, plot=FALSE)
par(mfcol=c(1,2), mai=c(0.4, 0.4, 0.7, 0.1), cex.main=0.9)
plot(ACF, main="ACF")
plot(PACF, main="PACF")
help(PACF)
help(pacf)
maxlag <- 15
ACF <- acf(x=as.matrix(xtsdata), lag.max=15, plot=FALSE)
PACF <- pacf(x=as.matrix(xtsdata), log.max=15, plot=FALSE)
par(mfcol=c(1,2), mai=c(0.4, 0.4, 0.7, 0.1), cex.main=0.9)
plot(ACF, main="ACF")
plot(PACF, main="PACF")
GARCH <- garchFit(~arma(1,0)+garch(1,1), data=xtsdata$Close, trace=TRUE)
f <- predict(GARCH, plot=TRUE, n.ahead=10)
?lm
setwd("/Users/tianyudu/Documents/Academics/EconForecasting/AnnEconForecast")
# May 16 2019
library(fpp2)
library(ggfortify)
library(forecast)
library(stats)
library(aTSA)
df <- read.csv("./data/CPIAUCSL.csv", header=TRUE, sep=",")
ts_data <- ts(df$CPIAUCSL,start=c(1947,1),frequency=12)
autoplot(ts_data) +
ggtitle("Consumer Price Index for All Urban Consumers: All Items (CPIAUCSL)") +
xlab("Date") +
ylab("CPI") +
theme(plot.title = element_text(size=8, face="bold"))
# Classical decomposition of target series.
components.ts <- decompose(ts_data)
plot(components.ts)
# The seasonal plot
ggseasonplot(ts_data,polar=TRUE)+
ggtitle("CPIAUCSL (Season plot)")+
theme(plot.title = element_text(size=8, face="bold"))
transformed <- diff(ts, lag=1, differences=1)
plot(components.ts)
transformed <- diff(ts, lag=1, differences=1)
ggsubseriesplot(ts_data)+
ggtitle("CPIAUCSL (Subseries plot)")+
ylab("number of deaths")+
theme(plot.title = element_text(size=8, face="bold"))
ACF <- Acf(transformed, plot=TRUE)
PACF <-Pacf(transformed, plot=TRUE)
# Determine coefficient of integration.
ndiffs(ts_data)
transformed <- diff(ts, lag=1, differences=2)
transformed <- diff(ts_data, lag=1, differences=2)
ggsubseriesplot(ts_data)+
ggtitle("CPIAUCSL (Subseries plot)")+
ylab("number of deaths")+
theme(plot.title = element_text(size=8, face="bold"))
ACF <- Acf(transformed, plot=TRUE)
PACF <-Pacf(transformed, plot=TRUE)
library(xts)
library(anytime)
ts <- xts(x=df[c("Exchange")], order.by=anytime(df$Date))
ts_all <- xts(x=df[c("Exchange")], order.by=anytime(df$Date))
head(df)
# ts_data <- ts(df$CPIAUCSL,start=c(1947,1),frequency=12)
ts_all <- xts(x=df[c("CPIAUCSL")], order.by=anytime(df$DATE))
autoplot(ts_data) +
ggtitle("Consumer Price Index for All Urban Consumers: All Items (CPIAUCSL)") +
xlab("Date") +
ylab("CPI") +
theme(plot.title = element_text(size=8, face="bold"))
autoplot(ts_all) +
ggtitle("Consumer Price Index for All Urban Consumers: All Items (CPIAUCSL)") +
xlab("Date") +
ylab("CPI") +
theme(plot.title = element_text(size=8, face="bold"))
# May 16 2019
library(fpp2)
library(ggfortify)
library(forecast)
library(stats)
library(aTSA)
library(xts)
library(anytime)
df <- read.csv("./data/CPIAUCSL.csv", header=TRUE, sep=",")
# ts_data <- ts(df$CPIAUCSL,start=c(1947,1),frequency=12)
ts_all <- xts(x=df[c("CPIAUCSL")], order.by=anytime(df$DATE))
autoplot(ts_all) +
ggtitle("Consumer Price Index for All Urban Consumers: All Items (CPIAUCSL)") +
xlab("Date") +
ylab("CPI") +
theme(plot.title = element_text(size=8, face="bold"))
# Classical decomposition of target series.
components.ts <- decompose(ts_all)
# Train and test spliting
train_size <- as.integer(0.8 * length(ts_all))
test_size <- length(ts_all) - train_size
ts_train <- head(ts_all, train_size)
ts_test <- tail(ts_all, test_size)
# Forecasting of naive preddictor, as a baseline model.
baseline_error <- mean(
na.omit(diff(ts_test)) ** 2
)
cat(baseline_error)
cat("Base line MSE: ", baseline_error)
# Determine coefficient of integration.
ndiffs(ts_data)
# Operation on Training Sets
# Determine coefficient of integration.
ndiffs(ts_data)
# Operation on Training Sets
# Determine coefficient of integration.
ndiffs(ts_train)
ts_train[100]
ts_train[1]
ts_train[12]
ts_train[train_size]
# Operations on the Training Set
# Determine coefficient of integration.
ndiffs(ts_train)
ggseasonplot(ts_data,polar=TRUE)+
ggtitle("CPIAUCSL (Season plot)")+
theme(plot.title = element_text(size=8, face="bold"))
# Operations on the Training Set
# Determine coefficient of integration.
ndiffs(ts_train)
# Operations on the Training Set
# Determine coefficient of integration.
cat("Order of Integration", ndiffs(ts_train))
transformed <- diff(ts_data, lag=1, differences=2)
transformed <- diff(ts_train, lag=1, differences=2)
ggsubseriesplot(ts_data)+
ggtitle("CPIAUCSL (Subseries plot)")+
ylab("number of deaths")+
theme(plot.title = element_text(size=8, face="bold"))
ACF <- Acf(transformed, plot=TRUE)
PACF <-Pacf(transformed, plot=TRUE)
ACF <- Acf(transformed, plot=TRUE)
ACF <- Acf(transformed, plot=TRUE) + title("T")
ACF <- Acf(transformed, plot=TRUE)
PACF <-Pacf(transformed, plot=TRUE)
autoplot(transformed) +
ggtitle("Differenced Series") +
xlab("Date") +
ylab("Transformed")
adf.test(transformed)
transformed <- diff(ts_train, lag=1, differences=3)
adf.test(transformed)
transformed <- diff(ts_train, lag=1, differences=1)
adf.test(transformed)
transformed <- diff(ts_train, lag=2, differences=1)
adf.test(transformed)
# ==== Fit and Evaluate the Model ====
model <- arima(ts, order = c(4,1,0))
# Find the Best ARIMA Profile
auto.arima(ts_train, max.order=30, stationary=FALSE, trace=TRUE)
# Find the Best ARIMA Profile
auto.arima(ts_train, max.order=100, stationary=FALSE, trace=TRUE)
ts_train
ts_train$CPIAUCSL
# Find the Best ARIMA Profile
auto.arima(ts_train$CPIAUCSL, max.order=100, stationary=FALSE, trace=TRUE)
# Find the Best ARIMA Profile
auto.arima(ts_train$CPIAUCSL, max.p=10, stationary=FALSE, trace=TRUE)
# Find the Best ARIMA Profile
auto.arima(ts_train$CPIAUCSL, max.p=10, max.q=10, max.d=10, stationary=FALSE, trace=TRUE)
# Find the Best ARIMA Profile
auto.arima(ts_train$CPIAUCSL, max.p=10, max.q=10, max.d=10, stationary=TRUE, trace=TRUE)
# Find the Best ARIMA Profile
auto.arima(ts_train$CPIAUCSL, max.p=10, max.q=10, max.d=10, stationary=FALSE, trace=TRUE, seasonal=TRUE)
# Find the Best ARIMA Profile
auto.arima(ts_train$CPIAUCSL, max.p=10, max.q=10, max.d=10, stationary=FALSE, trace=TRUE, seasonal=FALSE)
# Find the Best ARIMA Profile
auto.arima(ts_train$CPIAUCSL, max.p=10, max.P=10, max.q=10, max.Q=10, max.d=10, max.D=10, stationary=FALSE, trace=TRUE)
# Find the Best ARIMA Profile
c <- auto.arima(ts_train$CPIAUCSL, max.p=10, max.P=10, max.q=10, max.Q=10, max.d=10, max.D=10, stationary=FALSE, trace=TRUE)
c$coef
c$arma
# ==== Fit and Evaluate the Model ====
model <- arima(ts_train, order=c$arma)
# ==== Fit and Evaluate the Model ====
model <- arima(ts_train, order=c$var.coef)
c$var.coef
# ==== Fit and Evaluate the Model ====
model <- arima(ts_train, order=(2, 2, 2))
# Find the Best ARIMA Profile
auto.arima(ts_train$CPIAUCSL, max.p=10, max.P=10, max.q=10, max.Q=10, max.d=10, max.D=10, stationary=FALSE, trace=TRUE)
# ==== Fit and Evaluate the Model ====
model <- arima(ts_train, order=c(2, 2, 2))
res <- residuals(model)
mse <- mean(res**2)
rmse <- sqrt(mse)
err_abspec <- abs(res) / as.matrix(ts_train)
mape <- mean(
err_abspec[err_abspec != Inf]
)
cat("MSE:", mse, "RMSE:", rmse, "MAPE:", mape)
coeftest(model)
library(lmtest)
coeftest(model)
# ==== Fit and Evaluate the Model ====
profile <- c(2, 2, 2)
model <- arima(ts_train, order=profile)
res <- residuals(model)
mse <- mean(res**2)
rmse <- sqrt(mse)
err_abspec <- abs(res) / as.matrix(ts_train)
mape <- mean(
err_abspec[err_abspec != Inf]
)
cat("MSE:", mse, "RMSE:", rmse, "MAPE:", mape)
coeftest(model)
# Simple forecast
fore <- forecast::forecast(model, h=1, level=c(99))
autoplot(fore)
# Rolling forecast
rf <- c()
for (i in c(1: test_size)){
# Refit model
model <- arima(
head(ts_all, train_size+i-1),
# To predict the first element of the test set, we use the whole training set.
# To predict the k-th element of the test set (i.e. train_size+k th element), use all previouse train_size+k-1 elements.
order=profile
)
# Produce one step forecast
f <- forecast::forecast(model, h=1, level=c(99))
rf <- c(rf, f$mean)  # Add rolling forecast.
}
ts_rf <- ts(rf, start=time(ts_test)[1])
combined <- cbind("Rolling Forecast"=ts_rf, "Actual"=ts_test)
autoplot(combined) +
ggtitle("One Step Rolling Forecasting on Test Set") +
xlab("Date") +
ylab("Sunspot")
# Performance Metrics
mse_test <- mean((ts_rf - ts_test) ** 2)
rmse_test <- sqrt(mse_test)
cat("Test MSE:", mse, "RMSE:", rmse)
combined <- cbind("Rolling Forecast"=ts_rf, "Actual"=ts_test)
ts_rf <- ts(rf, start=time(ts_test)[1])
time(ts_test)
time(ts_test)[1]
rf
ts_rf <- xts(rf, start=time(ts_test)[1])
rf
len(rf)
length(rf)
length(ts_test)
ts_rf <- xts(x=rf, order.by=anytime(time(ts_test)))
ts_rf
combined <- cbind("Rolling Forecast"=ts_rf, "Actual"=ts_test)
autoplot(combined) +
ggtitle("One Step Rolling Forecasting on Test Set") +
xlab("Date") +
ylab("Sunspot")
# Performance Metrics
mse_test <- mean((ts_rf - ts_test) ** 2)
rmse_test <- sqrt(mse_test)
cat("Test MSE:", mse, "RMSE:", rmse)
ts_rf
head(ts_rf)
head(ts-train)
head(ts_train)
head(ts_test)
combined
auto(combined)
autoplot(combined)
plot(combined)
plot(combined)
plot(combined)
autoplot(combined, facets=FALSE) +
ggtitle("One Step Rolling Forecasting on Test Set") +
xlab("Date") +
ylab("Sunspot")
autoplot(combined, facets=FALSE, alpha=0.6) +
ggtitle("One Step Rolling Forecasting on Test Set") +
xlab("Date") +
ylab("Sunspot")
# Performance Metrics
mse_test <- mean((ts_rf - ts_test) ** 2)
rmse_test <- sqrt(mse_test)
cat("Test MSE:", mse, "RMSE:", rmse)
profile <- c(2, 2, 2)
model <- arima(ts_train, order=profile)
res <- residuals(model)
mse <- mean(res**2)
rmse <- sqrt(mse)
err_abspec <- abs(res) / as.matrix(ts_train)
mape <- mean(
err_abspec[err_abspec != Inf]
)
cat("MSE:", mse, "RMSE:", rmse, "MAPE:", mape)
# ==== Fit and Evaluate the Model ====
profile <- c(2, 0, 2)
model <- arima(ts_train, order=profile)
res <- residuals(model)
mse <- mean(res**2)
rmse <- sqrt(mse)
err_abspec <- abs(res) / as.matrix(ts_train)
mape <- mean(
err_abspec[err_abspec != Inf]
)
cat("MSE:", mse, "RMSE:", rmse, "MAPE:", mape)
profile <- c(2, 2, 2)
model <- arima(ts_train, order=profile)
train_res <- residuals(model)
train_mse <- mean(res**2)
train_rmse <- sqrt(mse)
err_abspec <- abs(res) / as.matrix(ts_train)
train_mape <- mean(
err_abspec[err_abspec != Inf]
)
cat("MSE:", train_mse, "RMSE:", train_rmse, "MAPE:", train_mape)
# May 16 2019
# Modify: Jun. 13 2019
library(fpp2)
library(ggfortify)
library(forecast)
library(stats)
library(aTSA)
library(lmtest)
library(xts)
library(anytime)
df <- read.csv("./data/CPIAUCSL.csv", header=TRUE, sep=",")
# ts_data <- ts(df$CPIAUCSL,start=c(1947,1),frequency=12)
ts_all <- xts(x=df[c("CPIAUCSL")], order.by=anytime(df$DATE))
autoplot(ts_all) +
ggtitle("Consumer Price Index for All Urban Consumers: All Items (CPIAUCSL)") +
xlab("Date") +
ylab("CPI") +
theme(plot.title = element_text(size=8, face="bold"))
# Train and test spliting
train_size <- as.integer(0.8 * length(ts_all))
test_size <- length(ts_all) - train_size
ts_train <- head(ts_all, train_size)
ts_test <- tail(ts_all, test_size)
# Forecasting of naive preddictor, as a baseline model.
baseline_error <- mean(
na.omit(diff(ts_test)) ** 2
)
cat("Base line MSE: ", baseline_error)
# Operations on the Training Set
# Determine coefficient of integration.
cat("Order of Integration: ", ndiffs(ts_train))
transformed <- diff(ts_train, lag=1, differences=2)
ACF <- Acf(transformed, plot=TRUE)
PACF <-Pacf(transformed, plot=TRUE)
autoplot(transformed) +
ggtitle("Differenced Series") +
xlab("Date") +
ylab("Transformed")
adf.test(transformed)
# Find the Best ARIMA Profile
auto.arima(ts_train$CPIAUCSL, max.p=10, max.P=10, max.q=10, max.Q=10, max.d=10, max.D=10, stationary=FALSE, trace=TRUE)
# ==== Fit and Evaluate the Model ====
profile <- c(2, 2, 2)
model <- arima(ts_train, order=profile)
train_res <- residuals(model)
train_mse <- mean(res**2)
train_rmse <- sqrt(mse)
err_abspec <- abs(res) / as.matrix(ts_train)
train_mape <- mean(
err_abspec[err_abspec != Inf]
)
cat("MSE:", train_mse, "RMSE:", train_rmse, "MAPE:", train_mape)
coeftest(model)
# Simple forecast
fore <- forecast::forecast(model, h=1, level=c(99))
autoplot(fore)
# Rolling forecast
rf <- c()
for (i in c(1: test_size)){
# Refit model
model <- arima(
head(ts_all, train_size+i-1),
# To predict the first element of the test set, we use the whole training set.
# To predict the k-th element of the test set (i.e. train_size+k th element), use all previouse train_size+k-1 elements.
order=profile
)
# Produce one step forecast
f <- forecast::forecast(model, h=1, level=c(99))
rf <- c(rf, f$mean)  # Add rolling forecast.
}
ts_rf <- xts(x=rf, order.by=anytime(time(ts_test)))
combined <- cbind("Rolling Forecast"=ts_rf, "Actual"=ts_test)
autoplot(combined, facets=FALSE, alpha=0.6) +
ggtitle("One Step Rolling Forecasting on Test Set") +
xlab("Date") +
ylab("Sunspot")
# Performance Metrics
mse_test <- mean((ts_rf - ts_test) ** 2)
rmse_test <- sqrt(mse_test)
cat("Test MSE:", mse, "RMSE:", rmse)
cat("Test MSE:", mse_test, "RMSE:", rmse_test)
cat("Training Set MSE:", mse_train, "RMSE:", rmse_train, "MAPE:", mape_train)
cat("Training Set MSE:", mse_train, "RMSE:", rmse_train, "MAPE:", mape_train)
adf.test(transformed)
# May 16 2019
# Modify: Jun. 13 2019
library(fpp2)
library(ggfortify)
library(forecast)
library(stats)
library(aTSA)
library(lmtest)
library(xts)
library(anytime)
df <- read.csv("./data/CPIAUCSL.csv", header=TRUE, sep=",")
# ts_data <- ts(df$CPIAUCSL,start=c(1947,1),frequency=12)
ts_all <- xts(x=df[c("CPIAUCSL")], order.by=anytime(df$DATE))
autoplot(ts_all) +
ggtitle("Consumer Price Index for All Urban Consumers: All Items (CPIAUCSL)") +
xlab("Date") +
ylab("CPI") +
theme(plot.title = element_text(size=8, face="bold"))
# Train and test spliting
train_size <- as.integer(0.8 * length(ts_all))
test_size <- length(ts_all) - train_size
ts_train <- head(ts_all, train_size)
ts_test <- tail(ts_all, test_size)
# Forecasting of naive preddictor, as a baseline model.
baseline_error <- mean(
na.omit(diff(ts_test)) ** 2
)
cat("Base line MSE: ", baseline_error)
# Operations on the Training Set
# Determine coefficient of integration.
cat("Order of Integration: ", ndiffs(ts_train))
transformed <- diff(ts_train, lag=1, differences=2)
ACF <- Acf(transformed, plot=TRUE)
PACF <-Pacf(transformed, plot=TRUE)
autoplot(transformed) +
ggtitle("Differenced Series") +
xlab("Date") +
ylab("Transformed")
adf.test(transformed)
# Find the Best ARIMA Profile
auto.arima(ts_train$CPIAUCSL, max.p=10, max.P=10, max.q=10, max.Q=10, max.d=10, max.D=10, stationary=FALSE, trace=TRUE)
# ==== Fit and Evaluate the Model ====
profile <- c(2, 2, 2)
model <- arima(ts_train, order=profile)
res <- residuals(model)
mse_train <- mean(res**2)
rmse_train <- sqrt(mse_train)
err_abspec <- abs(res) / as.matrix(ts_train)
mape_train <- mean(
err_abspec[err_abspec != Inf]
)
cat("Training Set MSE:", mse_train, "RMSE:", rmse_train, "MAPE:", mape_train)
coeftest(model)
# Simple forecast
fore <- forecast::forecast(model, h=1, level=c(99))
autoplot(fore)
# Rolling forecast
rf <- c()
for (i in c(1: test_size)){
# Refit model
model <- arima(
head(ts_all, train_size+i-1),
# To predict the first element of the test set, we use the whole training set.
# To predict the k-th element of the test set (i.e. train_size+k th element), use all previouse train_size+k-1 elements.
order=profile
)
# Produce one step forecast
f <- forecast::forecast(model, h=1, level=c(99))
rf <- c(rf, f$mean)  # Add rolling forecast.
}
ts_rf <- xts(x=rf, order.by=anytime(time(ts_test)))
combined <- cbind("Rolling Forecast"=ts_rf, "Actual"=ts_test)
autoplot(combined, facets=FALSE, alpha=0.6) +
ggtitle("One Step Rolling Forecasting on Test Set") +
xlab("Date") +
ylab("Sunspot")
# Performance Metrics
mse_test <- mean((ts_rf - ts_test) ** 2)
rmse_test <- sqrt(mse_test)
cat("Test MSE:", mse_test, "RMSE:", rmse_test)
