{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.24.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import os\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import constants\n",
    "import core.tools.metrics as metrics\n",
    "import core.tools.rnn_prepare as rnn_prepare\n",
    "import core.tools.visualize as visualize\n",
    "import core.tools.param_set_generator as param_set_generator\n",
    "import core.models.stacked_lstm as stacked_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hps_configs.mac_config import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameter sets generated: 6\n"
     ]
    }
   ],
   "source": [
    "param_set = param_set_generator.gen_hparam_set(main)\n",
    "param = param_set[0]\n",
    "file_dir = constants.DATA_DIR[\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoints(period, total):\n",
    "    \"\"\"\n",
    "    A helpful function for individual train method.\n",
    "    to generate checkpoint list with integers \n",
    "    for every PERIOD time steps and TOTAL time steps in total.\n",
    "    \"\"\"\n",
    "    ckps = [\n",
    "        period * x for x in range(1, total // period)\n",
    "    ]\n",
    "    return ckps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.    \n",
      "\tIndex type: datetime64[ns]    \n",
      "\tData type: float64\n",
      "StandardScaler applied, scaling based on the first 679 observations.\n",
      "Total 842 observations generated.\n",
      "Note: shape format: (num_obs, time_steps, num_inputs/outputs)\n",
      "X shape = (842, 6, 1), y shape = (842, 1, 1)\n",
      "Training and testing set generated,        \n",
      "X_train shape: (672, 6, 1)        \n",
      "y_train shape: (672, 1)        \n",
      "X_test shape: (85, 6, 1)        \n",
      "y_test shape: (85, 1)        \n",
      "X_validation shape: (85, 6, 1)        \n",
      "y_validation shape: (85, 1)\n",
      "Resetting Tensorflow defalut graph...\n",
      "Note: no gradient clipping is applied.            \n",
      "If possible gradient exploding detected (e.g. nan loss), try use clip_grad.\n",
      "Starting training session...\n",
      "Training model...\n",
      "\n",
      "Iteration [0], Training MSE 127.1071625; Validation MSE 149.9715881\n",
      "\n",
      "Iteration [100], Training MSE 0.7229499; Validation MSE 0.4551841\n",
      "Saving the model...\n",
      "Time taken for [150] epochs:  0:00:02.662637\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset.\n",
    "df_ready = rnn_prepare.prepare_dataset(\n",
    "    file_dir=file_dir,\n",
    "    periods=param[\"PERIODS\"],\n",
    "    order=param[\"ORDER\"],\n",
    "    remove=None,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Split dataset.\n",
    "(X_train, X_val, X_test,\n",
    " y_train, y_val, y_test) = rnn_prepare.split_dataset(\n",
    "    raw=df_ready,\n",
    "    train_ratio=param[\"TRAIN_RATIO\"],\n",
    "    val_ratio=param[\"VAL_RATIO\"],\n",
    "    lags=param[\"LAGS\"]\n",
    ")\n",
    "\n",
    "# The gross dataset excluding the test set.\n",
    "# Excluding the test set for isolation purpose.\n",
    "model_data_feed = {\n",
    "    \"X_train\": X_train,\n",
    "    \"X_val\": X_val,\n",
    "    \"y_train\": y_train,\n",
    "    \"y_val\": y_val,\n",
    "}\n",
    "\n",
    "# The checkpoint list \n",
    "ckps = checkpoints(param[\"epochs\"] // 10, param[\"epochs\"]) + [-1]\n",
    "\n",
    "predictions = stacked_lstm.exec_core(\n",
    "    param=param,\n",
    "    data=model_data_feed,\n",
    "    prediction_checkpoints=ckps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final result (validation set):\n",
      "Loss Summary:\n",
      "\tmae=0.5523725748062134\n",
      "\tmse=0.5186339616775513\n",
      "\trmse=0.7201624512672424\n",
      "\tmape=5.335463523864746\n"
     ]
    }
   ],
   "source": [
    "val_final = list(predictions.values())[-1][\"val\"]\n",
    "print(\"Final result (validation set):\")\n",
    "metric_test = metrics.merged_scores(\n",
    "    actual=pd.DataFrame(y_val),\n",
    "    pred=pd.DataFrame(val_final),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Visualize prediction during training.\n",
    "for set_name in [\"train\", \"val\"]:\n",
    "    pred = dict((e, val[set_name]) for e, val in predictions.items())\n",
    "    plt.close()\n",
    "    fig = visualize.plot_checkpoint_individual(\n",
    "        predictions=pred,\n",
    "        actual=model_data_feed[\"y_\" + set_name],\n",
    "        name=set_name)\n",
    "\n",
    "    if not os.path.exists(param[\"fig_path\"]):\n",
    "        os.makedirs(param[\"fig_path\"])\n",
    "    assert not param[\"fig_path\"].endswith(\"/\")\n",
    "    plt.savefig(param[\"fig_path\"] + \"/\" + f\"pred_record_{set_name}.svg\")\n",
    "    plt.close()\n",
    "\n",
    "fig = visualize.plot_checkpoint_combined(\n",
    "    predictions=predictions,\n",
    "    actual={\"train\": y_train, \"val\": y_val}\n",
    ")\n",
    "if not os.path.exists(param[\"fig_path\"]):\n",
    "    os.makedirs(param[\"fig_path\"])\n",
    "assert not param[\"fig_path\"].endswith(\"/\")\n",
    "plt.savefig(param[\"fig_path\"] + \"/\" + f\"pred_record_combined.svg\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
